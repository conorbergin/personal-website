---
title: How Generative AI has changed how I value art and writing
date: "2024-03-11"
tags:
    - AI
---

Having been conned into reading LLM output one too many times so I thought I'd outline why I feel so wronged by it.

Heres why I think people do it:

- **Money / Self promotion** -- You can create AI content and earn money from adsense and the like if you can convince people to click on it. Youtube is full of AI generated movie summaries. You can also directly sell AI generated products, Amazon is now full of AI generated ebooks, print on demand outfits like Redbubble are saturated with AI designs. I have come across a few technical blogs that post obvious LLM content in an attempt to build an online portfolio. Very slimy.

- **AI Enthusiasm** -- Some people genuinely enjoy creating AI content, and they are usually open about it not being their own work. You will sometimes see comments attributed to ChatGPT under questions on Reddit and HN. Less cynical, but still odd.

- **Memes / Trolling** -- I have no problem with this. 

I am not against LLMs by any means, I use ChatGPT almost as much as google these days, but I worry about this stuff clogging up the internet. I now find typos reassuring because I can be more confident I am reading something that was typed on an actual keyboard.

You don't have to be an AI expert to understand the control volume it operates under.

If you ask ChatGPT to produce an article comparing the benefits of learning Rust vs Go, it will only produce something passable because so much has already been written on the subject. If you then take this output an post it as a comment or an article, you are adding no new information to the internet. You can't be sure if any of it is true and you have nothing to cite apart from your own prompt. You would be doing everyone a favour by not posting it.

You might want to use an LLM to flesh out your original work, maybe you already have an essay outline with sources and references. The problem I have with this is you are treating prose like a decoration. Good prose is not just joining up a series of bullet points with transitional phrases. ChatGPT prepending every paragraph with some synonym of _Furthermore_ is not good prose. I would much prgefer to read your original bullet points than slogging though LLM soup.

I have similar feelings about AI art. I find it a bit tacky when I see AI generated header images on otherwise acceptable blog posts (unless you made the AI). You can criticize AI art for having six fingers or not being able to do lighting and reflections very well (imagine if Generative AI turned out to be able to do raytracing), but the fact of the matter my opinions wouldn't change even if it could.

Tom Friedman's [1000 Hours of Staring](https://www.moma.org/collection/works/114939) is a blank piece of paper that has been stared at for 1000 hours, does it have value? I catch myself wondering how seriously he took it, I would feel a bit cheated if I found out the 1000 hours were all done hungover, I hope he diligently timed every staring session and looked at the paper with deep intensity.

The original theories of value examine the embedded labour of a object. For example, the value of a horseshoe might be the labour required to extract the metal plus the labour required to forge a horse shoe plus labour required to repair damaged tools etc. We could try to apply this calculus to our AI art, but I already know the answer is effectively zero. I could further validate my hypothesis by offering my AI art for sale on the free market and having zero buyers at any price.

Conversely, using Dall-E I can generate an image in a few seconds that would take a professional artist tens of hours to replicate. Does it have value?

Model collapse is the idea that AI will become more useless as the pool of training data becomes more polluted with AI generated content. As it feeds on itself it will regress to some sort of mean, the entropy of the system will increase to a point that no useful information can be extracted from it. Accelerationists will sabotage corporate data silos with poisoned data sets, hoping the bring an end to the digital age.

